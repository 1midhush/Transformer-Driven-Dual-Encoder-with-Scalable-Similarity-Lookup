# Embeddingâ€‘Based Similarity Search with FAISS  
**Sirigudi Midhush** (Roll No.â€¯220150024)  

---

## ğŸ¯ Motivation  
Finding items by â€œmeaningâ€â€”whether sentences or imagesâ€”requires more than keyword matching or pixel comparison. We need systems that embed semantics into vector spaces and then perform nearestâ€‘neighbor search. This project demonstrates how to:  
1. Generate highâ€‘quality embeddings for text (Sentenceâ€‘BERT) and for imagesâ€¯+â€¯text (CLIP).  
2. Index millions of vectors with FAISS for subâ€‘10â€¯ms approximate search.  
3. Balance speed vs. accuracy via IVF and Product Quantization.  

---

## ğŸ”‘ Concepts & Topics Covered  
1. **Embedding Spaces** â€“ mapping sentences or images into highâ€‘dimensional vectors where distance â‰ˆ semantic dissimilarity.  
2. **Contrastive Learning** â€“ training encoders (SBERT, CLIP) to pull matching pairs together and push apart nonâ€‘matching.  
3. **Approximate Nearest Neighbors (ANN)** â€“ FAISS indexes (Flat, IVF, IVFâ€‘PQ) for subâ€‘linear search.  
4. **Vector Partitioning (IVF)** â€“ clustering vectors into Voronoi cells to reduce search scope.  
5. **Product Quantization (PQ)** â€“ compressing vectors into compact codes to speed distance computations.  
6. **Crossâ€‘Modal Retrieval** â€“ using CLIPâ€™s joint imageâ€‘text space for textâ†’image and imageâ†’image search.  

---

## ğŸ“‚ Repository Structure  

---

## ğŸ›  Workflow Summary  
1. **README review** â€“ highâ€‘level design & concepts.  
2. **Paperâ€¯1 (SBERT)** â€“ Siamese BERT for sentence vectors :contentReference[oaicite:0]{index=0}.  
3. **Paperâ€¯2 (CLIP)** â€“ contrastive imageâ€“text preâ€‘training :contentReference[oaicite:1]{index=1}.  
4. **Notebookâ€¯1** â€“ encode ~14.5â€¯K sentences, build Flat/IVF/IVFâ€‘PQ indexes, measure latency vs. accuracy.  
5. **Notebookâ€¯2** â€“ embed captions and images via CLIP, add FAISS indexes, demo textâ†’image & imageâ†’image retrieval.  

---

## ğŸ’¡ Reflections & Next Steps  
- **Insight:** IVFâ€‘PQ halves query time with minimal loss in neighbor quality.  
- **Future work:**  
  - Exact reâ€‘ranking of topâ€‘k ANN candidates.  
  - Lighter embedding models (MiniLM) for mobile deployment.  
  - REST API serving vector search in production.  

---

## ğŸ“– References  
1. Reimersâ€¯N., Gurevychâ€¯I. (2019). *Sentenceâ€‘BERT: Sentence Embeddings using Siamese BERTâ€‘Networks*. EMNLP. :contentReference[oaicite:2]{index=2}  
2. Radfordâ€¯A.â€¯etâ€¯al. (2021). *Learning Transferable Visual Models From Natural Language Supervision*. ICML. :contentReference[oaicite:3]{index=3}  
